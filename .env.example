# Environment configuration example
# Copy this file to .env and adjust values as needed

# Ollama configuration
OLLAMA_HOST=http://localhost:11434

# Model configuration for different tasks
# Default model for general document processing (balanced performance)
OLLAMA_DEFAULT_MODEL=qwen2.5vl:latest

# High-quality model for complex analysis (resource intensive)
OLLAMA_COMPLEX_MODEL=qwen2.5vl:72b

# Embedding model for vector search
OLLAMA_EMBEDDING_MODEL=nomic-embed-text:latest

# Alternative models (uncomment to use)
# OLLAMA_DEFAULT_MODEL=qwen2.5vl:72b-q8_0  # Good balance of quality and speed
# OLLAMA_DEFAULT_MODEL=mistral-small3.2:24b-instruct-2506-fp16  # Alternative option

# Data paths
DATA_PATH=data
DOCUMENTS_PATH=data/documents
CHROMA_PATH=data/chroma_db

# ChromaDB configuration (when using external ChromaDB)
CHROMA_HOST=http://localhost:8000

# Logging
LOG_LEVEL=INFO

# Session configuration
SESSION_TIMEOUT_HOURS=24

# Model selection strategy
# AUTO: automatically choose model based on query complexity
# FAST: always use default model for speed
# QUALITY: always use complex model for best results
MODEL_SELECTION_STRATEGY=AUTO

# Performance thresholds for auto model selection
# Switch to complex model for queries longer than this (characters)
COMPLEX_QUERY_THRESHOLD=200
# Switch to complex model for documents larger than this (MB)
COMPLEX_DOCUMENT_THRESHOLD=5

# Document processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
# Поддерживаемые типы файлов (через запятую)
SUPPORTED_FILE_TYPES=.txt,.md,.docx

# Resource management
# Maximum concurrent model requests
MAX_CONCURRENT_REQUESTS=2
# Timeout for model responses (seconds)
MODEL_TIMEOUT=300